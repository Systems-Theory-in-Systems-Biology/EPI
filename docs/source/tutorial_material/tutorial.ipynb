{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "This tutorial provides a full walk-through on how to apply EPI to a\n",
    "example problem. We only assume that you already installed `eulerpi`. The\n",
    "tutorial is divided in four sections:\n",
    "\n",
    "1.  [Introduction](#introduction)\n",
    "2.  [Define your data](#define-your-data)\n",
    "3.  [Define your model](#define-your-model)\n",
    "4.  [Inference](#inference)\n",
    "\n",
    "Let\\'s start!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "------------\n",
    "\n",
    "EPI is an algorithm to infere a parameter distribution $Q$ satisfying\n",
    "$Y = s(Q)$ given a (discrete) data probability distribution $y_i \\sim Y$\n",
    "and a model implementing the mapping $s: Q \\to Y$. The (forward) model\n",
    "describes the mapping from the parameter points $q_i$ to the data points\n",
    "$y_i$.\n",
    "\n",
    "In the following we will look at temperature data over the globe and a\n",
    "model for the dependence of the temperature $y_i$ on the latitude $q_i$.\n",
    "\n",
    "The goal is to derive the parameter distribution $\\Phi_Q$ from the data\n",
    "distribution $\\Phi_Y$. This is the inverse of what our (forward) model\n",
    "is providing. To solve the inverse problem, EPI uses the multi-dimension\n",
    "transformation formula:\n",
    "\n",
    "In the real world, problems with a known continous data distribution are\n",
    "very sparse. Instead, we often rely on discrete measurements. EPI start\n",
    "with discrete data points as input and derives a continous distribution\n",
    "using Kernel Density Estimation (KDE) techniques. From this data\n",
    "distribution the EPI algorithm derives the parameter distribution. To\n",
    "close the cycle between the data and parameters, we can again sample\n",
    "from this distribution and use the forward model to get a discrete\n",
    "distribution of the parameters.\n",
    "\n",
    "With this picture in mind, we can start to implement the temperature\n",
    "problem in eulerpi."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your data\n",
    "Your data needs to be stored in a `.csv` file in the following format:\n",
    "\n",
    "``` text\n",
    "datapoint_dim1, datapoint_dim2, datapoint_dim3, ..., datapoint_dimN\n",
    "datapoint_dim1, datapoint_dim2, datapoint_dim3, ..., datapoint_dimN\n",
    "datapoint_dim1, datapoint_dim2, datapoint_dim3, ..., datapoint_dimN\n",
    "...\n",
    "datapoint_dim1, datapoint_dim2, datapoint_dim3, ..., datapoint_dimN\n",
    "```\n",
    "\n",
    "Each of the lines defines a N dimensional datapoint. The\n",
    "`.csv` file will be loaded into an\n",
    "$\\mathrm{R}^{M \\times N}$ numpy matrix in EPI.\n",
    "\n",
    "In the following we will use the example data `TemperatureData.csv`. It has 455 datapoints with two dimensions each.\n",
    "Nonuniform data is not supported in EPI.\n",
    "Please download it from: [Download Temperature Data](https://systems-theory-in-systems-biology.github.io/EPI/_downloads/090dff47c31e511d0522cc9cc0cdb502/TemperatureData.csv) and make sure that it is located in the same path as this notebook. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your model\n",
    "\n",
    "Next you need to define your model. The most basic way is to derive from\n",
    "the `eulerpi.core.model.Model` base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from eulerpi.core.model import Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model inhereting from `Model` must implement the methods\n",
    "- `forward`\n",
    "- `jacobian`\n",
    "\n",
    "In addition it must implement the methods\n",
    "- `getcentral_param`\n",
    "- `getParamSamplingLimits`\n",
    "This provides the sampling algorithm with sensible starting values and boundary values.\n",
    "\n",
    "The jacobian for the temperature model is derived analytically and implemented explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class Temperature(Model):\n",
    "\n",
    "    param_dim = 1\n",
    "    data_dim = 1\n",
    "\n",
    "    PARAM_LIMITS = np.array([[0, np.pi / 2]])\n",
    "    CENTRAL_PARAM = np.array([np.pi / 4.0])\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        central_param: np.ndarray = CENTRAL_PARAM,\n",
    "        param_limits: np.ndarray = PARAM_LIMITS,\n",
    "        name: Optional[str] = None,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(central_param, param_limits, name=name, **kwargs)\n",
    "\n",
    "    def forward(self, param):\n",
    "        low_T = -30.0\n",
    "        high_T = 30.0\n",
    "        res = jnp.array(\n",
    "            [low_T + (high_T - low_T) * jnp.cos(jnp.abs(param[0]))]\n",
    "        )\n",
    "        return res\n",
    "\n",
    "    def jacobian(self, param):\n",
    "        return jnp.array([60.0 * jnp.sin(jnp.abs(param[0]))])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Now we can now use EPI to infer the parameter distribution from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Temperature' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Temperature' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Temperature' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Temperature' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Temperature' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meulerpi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minference\u001b[39;00m \u001b[39mimport\u001b[39;00m inference\n\u001b[1;32m      3\u001b[0m model \u001b[39m=\u001b[39m Temperature()\n\u001b[0;32m----> 4\u001b[0m inference(model, data \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mTemperatureData.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Uni/Masterarbeit/EPI/eulerpi/core/inference.py:122\u001b[0m, in \u001b[0;36minference\u001b[0;34m(model, data, inference_type, slices, num_processes, run_name, result_manager, continue_sampling, data_transformation, custom_data_transformation, n_components_pca, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[39mreturn\u001b[39;00m inference_dense_grid(\n\u001b[1;32m    113\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m    114\u001b[0m         data\u001b[39m=\u001b[39mdata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m \u001b[39melif\u001b[39;00m inference_type \u001b[39m==\u001b[39m InferenceType\u001b[39m.\u001b[39mMCMC:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mreturn\u001b[39;00m inference_mcmc(\n\u001b[1;32m    123\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    124\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    125\u001b[0m         data_transformation\u001b[39m=\u001b[39;49mdata_transformation,\n\u001b[1;32m    126\u001b[0m         result_manager\u001b[39m=\u001b[39;49mresult_manager,\n\u001b[1;32m    127\u001b[0m         slices\u001b[39m=\u001b[39;49mslices,\n\u001b[1;32m    128\u001b[0m         num_processes\u001b[39m=\u001b[39;49mnum_processes,\n\u001b[1;32m    129\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    131\u001b[0m \u001b[39melif\u001b[39;00m inference_type \u001b[39m==\u001b[39m InferenceType\u001b[39m.\u001b[39mSPARSE_GRID:\n\u001b[1;32m    132\u001b[0m     \u001b[39mreturn\u001b[39;00m inference_sparse_grid(\n\u001b[1;32m    133\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m    134\u001b[0m         data\u001b[39m=\u001b[39mdata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    140\u001b[0m     )\n",
      "File \u001b[0;32m~/Uni/Masterarbeit/EPI/eulerpi/core/sampling.py:372\u001b[0m, in \u001b[0;36minference_mcmc\u001b[0;34m(model, data, data_transformation, result_manager, slices, num_processes, num_runs, num_walkers, num_steps, num_burn_in_samples, thinning_factor, get_walker_acceptance)\u001b[0m\n\u001b[1;32m    356\u001b[0m slice_name \u001b[39m=\u001b[39m result_manager\u001b[39m.\u001b[39mget_slice_name(\u001b[39mslice\u001b[39m)\n\u001b[1;32m    357\u001b[0m result_manager\u001b[39m.\u001b[39msave_inference_information(\n\u001b[1;32m    358\u001b[0m     \u001b[39mslice\u001b[39m\u001b[39m=\u001b[39m\u001b[39mslice\u001b[39m,\n\u001b[1;32m    359\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m     thinning_factor\u001b[39m=\u001b[39mthinning_factor,\n\u001b[1;32m    367\u001b[0m )\n\u001b[1;32m    368\u001b[0m (\n\u001b[1;32m    369\u001b[0m     overall_params[slice_name],\n\u001b[1;32m    370\u001b[0m     overall_sim_results[slice_name],\n\u001b[1;32m    371\u001b[0m     overall_density_evals[slice_name],\n\u001b[0;32m--> 372\u001b[0m ) \u001b[39m=\u001b[39m run_emcee_sampling(\n\u001b[1;32m    373\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    374\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    375\u001b[0m     data_transformation\u001b[39m=\u001b[39;49mdata_transformation,\n\u001b[1;32m    376\u001b[0m     \u001b[39mslice\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mslice\u001b[39;49m,\n\u001b[1;32m    377\u001b[0m     result_manager\u001b[39m=\u001b[39;49mresult_manager,\n\u001b[1;32m    378\u001b[0m     num_runs\u001b[39m=\u001b[39;49mnum_runs,\n\u001b[1;32m    379\u001b[0m     num_walkers\u001b[39m=\u001b[39;49mnum_walkers,\n\u001b[1;32m    380\u001b[0m     num_steps\u001b[39m=\u001b[39;49mnum_steps,\n\u001b[1;32m    381\u001b[0m     num_burn_in_samples\u001b[39m=\u001b[39;49mnum_burn_in_samples,\n\u001b[1;32m    382\u001b[0m     thinning_factor\u001b[39m=\u001b[39;49mthinning_factor,\n\u001b[1;32m    383\u001b[0m     num_processes\u001b[39m=\u001b[39;49mnum_processes,\n\u001b[1;32m    384\u001b[0m )\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m get_walker_acceptance:\n\u001b[1;32m    387\u001b[0m     num_burn_in_steps \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(num_steps \u001b[39m*\u001b[39m num_runs \u001b[39m*\u001b[39m \u001b[39m0.01\u001b[39m)\n",
      "File \u001b[0;32m~/Uni/Masterarbeit/EPI/eulerpi/core/sampling.py:218\u001b[0m, in \u001b[0;36mrun_emcee_sampling\u001b[0;34m(model, data, data_transformation, slice, result_manager, num_processes, num_runs, num_walkers, num_steps, num_burn_in_samples, thinning_factor)\u001b[0m\n\u001b[1;32m    213\u001b[0m         logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    214\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mContinue sampling from saved sampler position in \u001b[39m\u001b[39m{\u001b[39;00mposition_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m         )\n\u001b[1;32m    217\u001b[0m     \u001b[39m# Run the sampler.\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     sampler_results, final_walker_positions \u001b[39m=\u001b[39m run_emcee_once(\n\u001b[1;32m    219\u001b[0m         model,\n\u001b[1;32m    220\u001b[0m         data,\n\u001b[1;32m    221\u001b[0m         data_transformation,\n\u001b[1;32m    222\u001b[0m         data_stdevs,\n\u001b[1;32m    223\u001b[0m         \u001b[39mslice\u001b[39;49m,\n\u001b[1;32m    224\u001b[0m         initial_walker_positions,\n\u001b[1;32m    225\u001b[0m         num_walkers,\n\u001b[1;32m    226\u001b[0m         num_steps,\n\u001b[1;32m    227\u001b[0m         num_processes,\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    230\u001b[0m     result_manager\u001b[39m.\u001b[39msave_run(\n\u001b[1;32m    231\u001b[0m         model, \u001b[39mslice\u001b[39m, run, sampler_results, final_walker_positions\n\u001b[1;32m    232\u001b[0m     )\n\u001b[1;32m    234\u001b[0m (\n\u001b[1;32m    235\u001b[0m     overall_params,\n\u001b[1;32m    236\u001b[0m     overall_sim_results,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[39mslice\u001b[39m, num_burn_in_samples, thinning_factor\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/Uni/Masterarbeit/EPI/eulerpi/core/sampling.py:110\u001b[0m, in \u001b[0;36mrun_emcee_once\u001b[0;34m(model, data, data_transformation, data_stdevs, slice, initial_walker_positions, num_walkers, num_steps, num_processes)\u001b[0m\n\u001b[1;32m    102\u001b[0m     sampler \u001b[39m=\u001b[39m emcee\u001b[39m.\u001b[39mEnsembleSampler(\n\u001b[1;32m    103\u001b[0m         num_walkers,\n\u001b[1;32m    104\u001b[0m         sampling_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m         args\u001b[39m=\u001b[39m[model, data, data_transformation, data_stdevs, \u001b[39mslice\u001b[39m],\n\u001b[1;32m    108\u001b[0m     )\n\u001b[1;32m    109\u001b[0m     \u001b[39m# Extract the final walker position and close the pool of worker processes.\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     final_walker_positions, _, _, _ \u001b[39m=\u001b[39m sampler\u001b[39m.\u001b[39;49mrun_mcmc(\n\u001b[1;32m    111\u001b[0m         initial_walker_positions, num_steps, tune\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, progress\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    114\u001b[0m     \u001b[39m# If the message equals \"Probability function returned NaN.\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(e) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mProbability function returned NaN.\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Uni/Masterarbeit/EPI/.venv/lib/python3.10/site-packages/emcee/ensemble.py:443\u001b[0m, in \u001b[0;36mEnsembleSampler.run_mcmc\u001b[0;34m(self, initial_state, nsteps, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     initial_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_previous_state\n\u001b[1;32m    442\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m \u001b[39mfor\u001b[39;00m results \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample(initial_state, iterations\u001b[39m=\u001b[39mnsteps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    444\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m# Store so that the ``initial_state=None`` case will work\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/Masterarbeit/EPI/.venv/lib/python3.10/site-packages/emcee/ensemble.py:344\u001b[0m, in \u001b[0;36mEnsembleSampler.sample\u001b[0;34m(self, initial_state, log_prob0, rstate0, blobs0, iterations, tune, skip_initial_state_check, thin_by, thin, store, progress, progress_kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     state\u001b[39m.\u001b[39mblobs \u001b[39m=\u001b[39m blobs0\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m state\u001b[39m.\u001b[39mlog_prob \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     state\u001b[39m.\u001b[39mlog_prob, state\u001b[39m.\u001b[39mblobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_log_prob(state\u001b[39m.\u001b[39;49mcoords)\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mshape(state\u001b[39m.\u001b[39mlog_prob) \u001b[39m!=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnwalkers,):\n\u001b[1;32m    346\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mincompatible input dimensions\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Uni/Masterarbeit/EPI/.venv/lib/python3.10/site-packages/emcee/ensemble.py:489\u001b[0m, in \u001b[0;36mEnsembleSampler.compute_log_prob\u001b[0;34m(self, coords)\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m         map_func \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m\n\u001b[0;32m--> 489\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(map_func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_prob_fn, p))\n\u001b[1;32m    491\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    492\u001b[0m     log_prob \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mfloat\u001b[39m(l[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from eulerpi.core.inference import inference\n",
    "\n",
    "model = Temperature()\n",
    "inference(model, data = \"TemperatureData.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the complexity of your model the sampling can take a long time. Due to this reason, not only the final results but also intermediate sampling results are saved. You can find them in the folder `Applications/Temperature/`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eulerpi-VaQQ5sfP-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42b2752a3dbae18c8c0b5227bcb491ccaa295e39fb9488759bcba272693a355d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
