import json
from typing import Dict, Optional, Tuple

import numpy as np

from eulerpi import logger

from .result_manager_utils import get_run_path


class ResultReader:
    """The result reader is responsible for loading the results of the inference from disk."""

    def __init__(self, model_name: str, run_name: str) -> None:
        self.model_name = model_name
        self.run_name = run_name
        self.inference_information = self.get_inference_information()

    def get_inference_information(self) -> Dict:
        """Load the inference information from the inference_information.json file.

        Returns:
            Dict: The inference information.
        """
        # return the Dict directly if already set
        if hasattr(self, "inference_information"):
            return self.inference_information

        run_path = get_run_path(self.model_name, self.run_name)
        with open(run_path + "/inference_information.json", "r") as file:
            inference_information = json.load(file)

        return inference_information

    def load_inference_results(
        self,
        num_burn_in_samples: Optional[int] = None,
        thinning_factor: Optional[int] = None,
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """Load the inference results generated by EPI.

        Args:
            num_burn_in_samples(int, optional): Number of samples that will be ignored per chain (i.e. walker). Only for mcmc inference. Default is None and uses the value that was used for the inference stored in inference_information.json.
            thinning_factor(int, optional): Thinning factor that will be used to thin the Markov chain. Only for mcmc inference. Default is None and uses the value that was used for the inference stored in each inference_information.json.

        Returns:
            typing.Tuple[np.ndarray, np.ndarray, np.ndarray]: The parameters, the pushforward of the parameters, and the density evaluations.

        """
        run_path = get_run_path(self.model_name, self.run_name)

        # load information from json file
        with open(run_path + "/inference_information.json", "r") as file:
            inference_information = json.load(file)

        if inference_information["inference_type"] == "MCMC":
            return self.load_mcmc_inference_results(
                inference_information, num_burn_in_samples, thinning_factor
            )

        if num_burn_in_samples is not None or thinning_factor is not None:
            logger.info(
                f"For inference type {inference_information['inference_type']}, num_burn_in_samples and thinning_factor are ignored."
            )

        return self.load_grid_based_inference_results()

    def load_mcmc_inference_results(
        self,
        inference_information: Dict,
        num_burn_in_samples: Optional[int] = None,
        thinning_factor: Optional[int] = None,
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """Load the inference results generated by EPI using MCMC.

        Args:
            num_burn_in_samples (int, optional): . Number of samples that will be ignored per chain (i.e. walker). Default is None and uses the value that was used for the inference stored in inference_information.json.
            thinning_factor(int, optional): Thinning factor that will be used to thin the Markov chain. Default is None and uses the value that was used for the inference stored in each inference_information.json.

        Returns:
            Tuple[np.ndarray, np.ndarray, np.ndarray]: The parameters, the pushforward of the parameters, and the density evaluations.
        """
        run_path = get_run_path(self.model_name, self.run_name)

        # use default values saved in inference_information if not specified
        if num_burn_in_samples is None:
            num_burn_in_samples = inference_information["num_burn_in_samples"]

        if thinning_factor is None:
            thinning_factor = inference_information["thinning_factor"]

        num_steps = inference_information["num_steps"]
        num_walkers = inference_information["num_walkers"]

        # load samples from raw chains
        for i in range(inference_information["num_runs"]):
            params_current_chain = np.loadtxt(
                run_path + f"/Params/raw_params_{i}.csv",
                delimiter=",",
                ndmin=2,
            )
            pushforward_evals_current_chain = np.loadtxt(
                run_path + f"/PushforwardEvals/raw_pushforward_evals_{i}.csv",
                delimiter=",",
                ndmin=2,
            )
            density_evals_current_chain = np.loadtxt(
                run_path + f"/DensityEvals/raw_density_evals_{i}.csv",
                delimiter=",",
            )
            if i == 0:
                param_dim = params_current_chain.shape[1]
                data_dim = pushforward_evals_current_chain.shape[1]
                params = params_current_chain.reshape(
                    num_steps, num_walkers, param_dim
                )
                pushforward_evals = pushforward_evals_current_chain.reshape(
                    num_steps, num_walkers, data_dim
                )
                density_evals = density_evals_current_chain.reshape(
                    num_steps, num_walkers, 1
                )
            else:
                density_evals = np.concatenate(
                    (
                        density_evals,
                        density_evals_current_chain.reshape(
                            num_steps, num_walkers, 1
                        ),
                    )
                )
                pushforward_evals = np.concatenate(
                    (
                        pushforward_evals,
                        pushforward_evals_current_chain.reshape(
                            num_steps, num_walkers, data_dim
                        ),
                    )
                )
                params = np.concatenate(
                    (
                        params,
                        params_current_chain.reshape(
                            num_steps, num_walkers, param_dim
                        ),
                    )
                )

        # thin and burn in
        return (
            params[num_burn_in_samples::thinning_factor, :, :].reshape(
                -1, param_dim
            ),
            pushforward_evals[
                num_burn_in_samples::thinning_factor, :, :
            ].reshape(-1, data_dim),
            density_evals[num_burn_in_samples::thinning_factor, :, :].reshape(
                -1, 1
            ),
        )

    def load_grid_based_inference_results(
        self,
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """Load the inference results generated by EPI using grid-based inference.

        Returns:
            Tuple[np.ndarray, np.ndarray, np.ndarray]: The parameters, the pushforward of the parameters, and the density evaluations.
        """
        run_path = get_run_path(self.model_name, self.run_name)

        param_chain = np.loadtxt(
            run_path + "/params.csv",
            delimiter=",",
            ndmin=2,
        )
        pushforward_evals = np.loadtxt(
            run_path + "/pushforward_evals.csv",
            delimiter=",",
            ndmin=2,
        )
        density_evals = np.loadtxt(
            run_path + "/density_evals.csv",
            delimiter=",",
        )
        return (
            param_chain,
            pushforward_evals,
            density_evals,
        )
